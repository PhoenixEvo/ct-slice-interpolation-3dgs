{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Visualization & Figure Generation\n",
    "\n",
    "Generate all publication-ready figures:\n",
    "1. Qualitative slice comparisons (GT vs all methods)\n",
    "2. Error maps\n",
    "3. Z-profile analysis\n",
    "4. ROI-specific analysis\n",
    "5. Training curve analysis for 3DGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Drive and setup\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!pip install nibabel SimpleITK scikit-image PyYAML tqdm seaborn -q\n",
    "\n",
    "import sys, os\n",
    "PROJECT_ROOT = \"/content/drive/MyDrive/TLCN\"\n",
    "sys.path.insert(0, PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from src.utils.config import load_config\n",
    "from src.utils.seed import set_seed\n",
    "from src.data.ct_org_loader import CTORGLoader\n",
    "from src.data.sparse_simulator import SparseSimulator\n",
    "from src.models.classical_interp import ClassicalInterpolator\n",
    "from src.evaluation.metrics import compute_psnr, compute_ssim, evaluate_volume\n",
    "from src.evaluation.visualization import (\n",
    "    plot_slice_comparison, plot_error_map,\n",
    "    plot_training_curves, plot_z_error_profile\n",
    ")\n",
    "\n",
    "config = load_config(os.path.join(PROJECT_ROOT, \"configs/default.yaml\"))\n",
    "set_seed(config[\"training\"][\"seed\"])\n",
    "\n",
    "OUTPUT_ROOT = config[\"data\"][\"output_root\"]\n",
    "FIG_DIR = os.path.join(OUTPUT_ROOT, \"figures\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "# Data loader\n",
    "loader = CTORGLoader(\n",
    "    dataset_root=config[\"data\"][\"dataset_root\"],\n",
    "    hu_min=config[\"data\"][\"hu_min\"],\n",
    "    hu_max=config[\"data\"][\"hu_max\"],\n",
    ")\n",
    "available_cases = loader.get_available_cases()\n",
    "split = CTORGLoader.get_split(\n",
    "    available_cases,\n",
    "    config[\"data\"][\"test_cases\"],\n",
    "    config[\"data\"][\"val_cases\"],\n",
    ")\n",
    "\n",
    "print(f\"Output directory: {FIG_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: load 3DGS predictions for a case\n",
    "def load_3dgs_predictions(case_idx, R, output_root):\n",
    "    \"\"\"Load trained 3DGS model and render predictions.\"\"\"\n",
    "    from src.training.trainer_3dgs import Trainer3DGS\n",
    "    from src.models.gaussian_volume import GaussianVolume\n",
    "    from src.models.slice_renderer import SliceRenderer\n",
    "    \n",
    "    ckpt_dir = os.path.join(output_root, \"3dgs\", f\"R{R}\", f\"case_{case_idx}\")\n",
    "    ckpt_path = os.path.join(ckpt_dir, \"final.pt\")\n",
    "    \n",
    "    if not os.path.exists(ckpt_path):\n",
    "        print(f\"  Checkpoint not found: {ckpt_path}\")\n",
    "        return None\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    \n",
    "    volume_shape = checkpoint[\"volume_shape\"]\n",
    "    target_indices = checkpoint[\"target_indices\"]\n",
    "    \n",
    "    # Reconstruct model\n",
    "    n = checkpoint[\"positions\"].shape[0]\n",
    "    model = GaussianVolume(n, volume_shape, device)\n",
    "    with torch.no_grad():\n",
    "        model.positions.data = checkpoint[\"positions\"].to(device)\n",
    "        model.log_scales.data = checkpoint[\"log_scales\"].to(device)\n",
    "        model.raw_opacity.data = checkpoint[\"raw_opacity\"].to(device)\n",
    "        model.intensity.data = checkpoint[\"intensity\"].to(device)\n",
    "    \n",
    "    # Render\n",
    "    renderer = SliceRenderer(\n",
    "        volume_shape[0], volume_shape[1],\n",
    "        tile_size=16, z_threshold=3.0\n",
    "    ).to(device)\n",
    "    \n",
    "    params = model.get_params()\n",
    "    H, W = volume_shape[0], volume_shape[1]\n",
    "    results = np.zeros((H, W, len(target_indices)), dtype=np.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, z_idx in enumerate(target_indices):\n",
    "            rendered = renderer(\n",
    "                params[\"positions\"], params[\"scales\"],\n",
    "                params[\"opacity\"], params[\"intensity\"],\n",
    "                float(z_idx)\n",
    "            )\n",
    "            rendered = torch.clamp(rendered, 0.0, 1.0)\n",
    "            results[:, :, i] = rendered.squeeze().cpu().numpy()\n",
    "    \n",
    "    del model, renderer\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return results, target_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Qualitative comparison on best/worst cases\n",
    "R = 2\n",
    "simulator = SparseSimulator(sparse_ratio=R)\n",
    "\n",
    "# Pick 3 diverse test cases\n",
    "viz_cases = split[\"test\"][:3]\n",
    "\n",
    "for case_idx in viz_cases:\n",
    "    print(f\"\\nGenerating figures for case {case_idx}...\")\n",
    "    \n",
    "    volume, labels, _ = loader.load_and_preprocess(case_idx)\n",
    "    sparse_data = simulator.simulate(volume)\n",
    "    \n",
    "    # Classical interpolation\n",
    "    classical_results = ClassicalInterpolator.interpolate_all_methods(\n",
    "        sparse_data[\"observed_slices\"],\n",
    "        sparse_data[\"observed_indices\"],\n",
    "        sparse_data[\"target_indices\"],\n",
    "    )\n",
    "    \n",
    "    # Try loading 3DGS predictions\n",
    "    gs_result = load_3dgs_predictions(case_idx, R, OUTPUT_ROOT)\n",
    "    \n",
    "    # Pick a mid-volume slice\n",
    "    target_idx = len(sparse_data[\"target_indices\"]) // 2\n",
    "    z_val = sparse_data[\"target_indices\"][target_idx]\n",
    "    gt_slice = sparse_data[\"target_slices\"][:, :, target_idx]\n",
    "    \n",
    "    predictions = {\n",
    "        \"Nearest\": classical_results[\"nearest\"][:, :, target_idx],\n",
    "        \"Linear\": classical_results[\"linear\"][:, :, target_idx],\n",
    "        \"Cubic\": classical_results[\"cubic\"][:, :, target_idx],\n",
    "    }\n",
    "    \n",
    "    if gs_result is not None:\n",
    "        gs_preds, gs_targets = gs_result\n",
    "        # Find matching target index\n",
    "        gs_target_list = list(gs_targets)\n",
    "        if z_val in gs_target_list:\n",
    "            gs_idx = gs_target_list.index(z_val)\n",
    "            predictions[\"3DGS (Ours)\"] = gs_preds[:, :, gs_idx]\n",
    "    \n",
    "    # Determine zoom region (center crop around organ)\n",
    "    H, W = gt_slice.shape\n",
    "    zoom = (H//4, 3*H//4, W//4, 3*W//4)\n",
    "    \n",
    "    # Plot comparison with zoom\n",
    "    fig = plot_slice_comparison(\n",
    "        gt_slice, predictions, z_idx=z_val,\n",
    "        save_path=os.path.join(FIG_DIR, f\"comparison_case{case_idx}_z{z_val}.png\"),\n",
    "        zoom_region=zoom,\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot error maps\n",
    "    fig = plot_error_map(\n",
    "        gt_slice, predictions, z_idx=z_val,\n",
    "        save_path=os.path.join(FIG_DIR, f\"error_case{case_idx}_z{z_val}.png\"),\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: Z-axis error profile for 3DGS\n",
    "print(\"\\nGenerating z-axis error profiles...\")\n",
    "\n",
    "sample_case = split[\"test\"][0]\n",
    "\n",
    "for R in config[\"data\"][\"sparse_ratios\"]:\n",
    "    gs_result = load_3dgs_predictions(sample_case, R, OUTPUT_ROOT)\n",
    "    \n",
    "    if gs_result is not None:\n",
    "        gs_preds, target_indices = gs_result\n",
    "        volume, _, _ = loader.load_and_preprocess(sample_case)\n",
    "        simulator = SparseSimulator(sparse_ratio=R)\n",
    "        sparse_data = simulator.simulate(volume)\n",
    "        \n",
    "        eval_result = evaluate_volume(\n",
    "            gs_preds,\n",
    "            sparse_data[\"target_slices\"],\n",
    "            sparse_data[\"target_indices\"],\n",
    "        )\n",
    "        \n",
    "        fig = plot_z_error_profile(\n",
    "            eval_result[\"per_slice\"],\n",
    "            method_name=f\"3DGS (R={R})\",\n",
    "            save_path=os.path.join(FIG_DIR, f\"z_profile_case{sample_case}_R{R}.png\"),\n",
    "        )\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "print(\"Z-axis profiles generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Training curves for a sample 3DGS run\n",
    "print(\"\\nLoading training history...\")\n",
    "\n",
    "sample_case = split[\"test\"][0]\n",
    "R = 2\n",
    "history_path = os.path.join(OUTPUT_ROOT, \"3dgs\", f\"R{R}\", f\"case_{sample_case}\", \"history.json\")\n",
    "\n",
    "if os.path.exists(history_path):\n",
    "    with open(history_path) as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    fig = plot_training_curves(\n",
    "        history,\n",
    "        save_path=os.path.join(FIG_DIR, f\"training_curves_case{sample_case}_R{R}.png\"),\n",
    "    )\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print(\"Training curves plotted.\")\n",
    "else:\n",
    "    print(f\"History not found: {history_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: Organ-specific visualization (ROI analysis)\n",
    "print(\"\\nGenerating organ-specific analysis...\")\n",
    "\n",
    "sample_case = split[\"test\"][0]\n",
    "volume, labels, _ = loader.load_and_preprocess(sample_case)\n",
    "\n",
    "if labels is not None:\n",
    "    R = 2\n",
    "    simulator = SparseSimulator(sparse_ratio=R)\n",
    "    sparse_data = simulator.simulate(volume)\n",
    "    \n",
    "    # Pick a slice with multiple organs\n",
    "    target_idx = len(sparse_data[\"target_indices\"]) // 2\n",
    "    z_val = sparse_data[\"target_indices\"][target_idx]\n",
    "    gt_slice = volume[:, :, z_val]\n",
    "    label_slice = labels[:, :, z_val]\n",
    "    \n",
    "    # Create organ overlay\n",
    "    organ_names = config[\"eval\"][\"organ_labels\"]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # CT slice\n",
    "    axes[0].imshow(gt_slice, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0].set_title('CT Slice')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Label overlay\n",
    "    axes[1].imshow(gt_slice, cmap='gray', vmin=0, vmax=1)\n",
    "    masked = np.ma.masked_where(label_slice == 0, label_slice)\n",
    "    axes[1].imshow(masked, cmap='tab10', alpha=0.4, vmin=0, vmax=6)\n",
    "    axes[1].set_title('Organ Overlay')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Label map\n",
    "    axes[2].imshow(label_slice, cmap='tab10', vmin=0, vmax=6)\n",
    "    axes[2].set_title('Segmentation Labels')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = []\n",
    "    for name, val in organ_names.items():\n",
    "        if val in np.unique(label_slice):\n",
    "            color = plt.cm.tab10(val / 6)\n",
    "            legend_elements.append(Patch(facecolor=color, label=f\"{name} ({val})\"))\n",
    "    axes[2].legend(handles=legend_elements, loc='lower right', fontsize=8)\n",
    "    \n",
    "    plt.suptitle(f'Organ Segmentation - Volume {sample_case}, z={z_val}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, f\"organ_overlay_case{sample_case}.png\"), dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No labels available for this case.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: list all generated figures\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generated Figures\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig_files = sorted(Path(FIG_DIR).glob(\"*.png\"))\n",
    "for f in fig_files:\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f\"  {f.name} ({size_kb:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nTotal: {len(fig_files)} figures saved to {FIG_DIR}\")\n",
    "print(\"\\nAll visualizations complete!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
